{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rdbraatz/data-driven-prediction-of-battery-cycle-life-before-capacity-degradation/blob/master/Load%20Data.ipynb\n",
    "\n",
    "remove_keys = [\n",
    "  # FOLLOWS THE ORIGINAL REPO\n",
    "  # remove batteries that do not reach 80% capacity\n",
    "  'b1c8', 'b1c10', 'b1c12', 'b1c13', 'b1c22',      \n",
    "  # remove batteries from batch 2 that are moved to batch 1\n",
    "  'b2c7', 'b2c8', 'b2c9', 'b2c15', 'b2c16',      \n",
    "  # remove noisy channels from batch3\n",
    "  'b3c37', 'b3c2', 'b3c23', 'b3c32', 'b3c42', 'b3c43',\n",
    "  \n",
    "  # NEWLY DELETED HERE\n",
    "  # remove outlier with abnormal capacity\n",
    "  'b1c0', 'b1c18', 'b2c12', 'b2c44'\n",
    "]\n",
    "# There are four cells from batch1 that carried into batch2, we'll remove the data from batch2\n",
    "# and put it with the correct cell from batch1\n",
    "batch2_keys = ['b2c7', 'b2c8', 'b2c9', 'b2c15', 'b2c16']\n",
    "batch1_keys = ['b1c0', 'b1c1', 'b1c2', 'b1c3', 'b1c4']\n",
    "add_len = [662, 981, 1060, 208, 482]\n",
    "\n",
    "temperature_feature_interval = 1\n",
    "current_feature_interval = 1\n",
    "\n",
    "cap_outlier_diff_threshold = 0.015\n",
    "\n",
    "curve_ratio_min = 0.5\n",
    "curve_ratio_max = 0.99\n",
    "curve_ratio_steps = 9\n",
    "curve_ratio_digits = 2\n",
    "curve_ratio_step_size = (curve_ratio_max - curve_ratio_min) / curve_ratio_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = './data/MIT Stanford battery dataset/'\n",
    "batch1 = pickle.load(open(os.path.join(data_dir_path,'batch1.pkl'), 'rb'))\n",
    "batch2 = pickle.load(open(os.path.join(data_dir_path,'batch2.pkl'), 'rb'))\n",
    "batch3 = pickle.load(open(os.path.join(data_dir_path,'batch3.pkl'), 'rb'))\n",
    "\n",
    "for i, bk in enumerate(batch1_keys):\n",
    "  batch1[bk]['cycle_life'] = batch1[bk]['cycle_life'] + add_len[i]\n",
    "  for j in batch1[bk]['summary'].keys():\n",
    "    if j == 'cycle':\n",
    "      batch1[bk]['summary'][j] = np.hstack((batch1[bk]['summary'][j], batch2[batch2_keys[i]]['summary'][j] + len(batch1[bk]['summary'][j])))\n",
    "    else:\n",
    "      batch1[bk]['summary'][j] = np.hstack((batch1[bk]['summary'][j], batch2[batch2_keys[i]]['summary'][j]))\n",
    "  last_cycle = len(batch1[bk]['cycles'].keys())\n",
    "  for j, jk in enumerate(batch2[batch2_keys[i]]['cycles'].keys()):\n",
    "    batch1[bk]['cycles'][str(last_cycle + j)] = batch2[batch2_keys[i]]['cycles'][jk]\n",
    "    \n",
    "batch = {**batch1, **batch2, **batch3}\n",
    "for key in remove_keys:\n",
    "  del batch[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temps = []\n",
    "min_temps = []\n",
    "for key in batch.keys():\n",
    "  max_temps.append(np.max(batch[key]['summary']['Tmax']))\n",
    "  min_temps.append(np.min(batch[key]['summary']['Tmin'][np.nonzero(batch[key]['summary']['Tmin'])]))\n",
    "max_temp = np.max(max_temps)\n",
    "min_temp = np.min(min_temps)\n",
    "\n",
    "max_currents = []\n",
    "min_currents = []\n",
    "for key in batch.keys():\n",
    "  for cycle in batch[key]['cycles'].keys():\n",
    "    max_currents.append(np.max(batch[key]['cycles'][cycle]['I']))\n",
    "    min_currents.append(np.min(batch[key]['cycles'][cycle]['I']))\n",
    "max_current = np.max(max_currents)\n",
    "min_current = np.min(min_currents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed b1c1 with 2154 cycles\n",
      "Preprocessed b1c2 with 2233 cycles\n",
      "Preprocessed b1c3 with 1430 cycles\n",
      "Preprocessed b1c4 with 1704 cycles\n",
      "Preprocessed b1c5 with 1072 cycles\n",
      "Preprocessed b1c6 with 634 cycles\n",
      "Preprocessed b1c7 with 868 cycles\n",
      "Preprocessed b1c9 with 1052 cycles\n",
      "Preprocessed b1c11 with 786 cycles\n",
      "Preprocessed b1c14 with 878 cycles\n",
      "Preprocessed b1c15 with 717 cycles\n",
      "Preprocessed b1c16 with 860 cycles\n",
      "Preprocessed b1c17 with 855 cycles\n",
      "Preprocessed b1c19 with 786 cycles\n",
      "Preprocessed b1c20 with 532 cycles\n",
      "Preprocessed b1c21 with 557 cycles\n",
      "Preprocessed b1c23 with 1012 cycles\n",
      "Preprocessed b1c24 with 1013 cycles\n",
      "Preprocessed b1c25 with 852 cycles\n",
      "Preprocessed b1c26 with 868 cycles\n",
      "Preprocessed b1c27 with 840 cycles\n",
      "Preprocessed b1c28 with 858 cycles\n",
      "Preprocessed b1c29 with 915 cycles\n",
      "Preprocessed b1c30 with 707 cycles\n",
      "Preprocessed b1c31 with 874 cycles\n",
      "Preprocessed b1c32 with 729 cycles\n",
      "Preprocessed b1c33 with 755 cycles\n",
      "Preprocessed b1c34 with 740 cycles\n",
      "Preprocessed b1c35 with 701 cycles\n",
      "Preprocessed b1c36 with 702 cycles\n",
      "Preprocessed b1c37 with 646 cycles\n",
      "Preprocessed b1c38 with 615 cycles\n",
      "Preprocessed b1c39 with 623 cycles\n",
      "Preprocessed b1c40 with 964 cycles\n",
      "Preprocessed b1c41 with 1047 cycles\n",
      "Preprocessed b1c42 with 700 cycles\n",
      "Preprocessed b1c43 with 649 cycles\n",
      "Preprocessed b1c44 with 614 cycles\n",
      "Preprocessed b1c45 with 597 cycles\n",
      "Preprocessed b2c0 with 323 cycles\n",
      "Preprocessed b2c1 with 169 cycles\n",
      "Preprocessed b2c2 with 461 cycles\n",
      "Preprocessed b2c3 with 360 cycles\n",
      "Preprocessed b2c4 with 470 cycles\n",
      "Preprocessed b2c5 with 504 cycles\n",
      "Preprocessed b2c6 with 544 cycles\n",
      "Preprocessed b2c10 with 595 cycles\n",
      "Preprocessed b2c11 with 504 cycles\n",
      "Preprocessed b2c13 with 518 cycles\n",
      "Preprocessed b2c14 with 508 cycles\n",
      "Preprocessed b2c17 with 524 cycles\n",
      "Preprocessed b2c18 with 522 cycles\n",
      "Preprocessed b2c19 with 488 cycles\n",
      "Preprocessed b2c20 with 530 cycles\n",
      "Preprocessed b2c21 with 519 cycles\n",
      "Preprocessed b2c22 with 539 cycles\n",
      "Preprocessed b2c23 with 559 cycles\n",
      "Preprocessed b2c24 with 523 cycles\n",
      "Preprocessed b2c25 with 486 cycles\n",
      "Preprocessed b2c26 with 497 cycles\n",
      "Preprocessed b2c27 with 494 cycles\n",
      "Preprocessed b2c28 with 540 cycles\n",
      "Preprocessed b2c29 with 521 cycles\n",
      "Preprocessed b2c30 with 506 cycles\n",
      "Preprocessed b2c31 with 518 cycles\n",
      "Preprocessed b2c32 with 543 cycles\n",
      "Preprocessed b2c33 with 544 cycles\n",
      "Preprocessed b2c34 with 523 cycles\n",
      "Preprocessed b2c35 with 485 cycles\n",
      "Preprocessed b2c36 with 557 cycles\n",
      "Preprocessed b2c37 with 501 cycles\n",
      "Preprocessed b2c38 with 486 cycles\n",
      "Preprocessed b2c39 with 477 cycles\n",
      "Preprocessed b2c40 with 529 cycles\n",
      "Preprocessed b2c41 with 449 cycles\n",
      "Preprocessed b2c42 with 491 cycles\n",
      "Preprocessed b2c43 with 484 cycles\n",
      "Preprocessed b2c45 with 513 cycles\n",
      "Preprocessed b2c46 with 448 cycles\n",
      "Preprocessed b2c47 with 744 cycles\n",
      "Preprocessed b3c0 with 1007 cycles\n",
      "Preprocessed b3c1 with 1061 cycles\n",
      "Preprocessed b3c3 with 1113 cycles\n",
      "Preprocessed b3c4 with 1046 cycles\n",
      "Preprocessed b3c5 with 826 cycles\n",
      "Preprocessed b3c6 with 665 cycles\n",
      "Preprocessed b3c7 with 1834 cycles\n",
      "Preprocessed b3c8 with 826 cycles\n",
      "Preprocessed b3c9 with 1037 cycles\n",
      "Preprocessed b3c10 with 1076 cycles\n",
      "Preprocessed b3c11 with 815 cycles\n",
      "Preprocessed b3c12 with 930 cycles\n",
      "Preprocessed b3c13 with 814 cycles\n",
      "Preprocessed b3c14 with 856 cycles\n",
      "Preprocessed b3c15 with 874 cycles\n",
      "Preprocessed b3c16 with 1636 cycles\n",
      "Preprocessed b3c17 with 1313 cycles\n",
      "Preprocessed b3c18 with 1144 cycles\n",
      "Preprocessed b3c19 with 1153 cycles\n",
      "Preprocessed b3c20 with 811 cycles\n",
      "Preprocessed b3c21 with 770 cycles\n",
      "Preprocessed b3c22 with 1000 cycles\n",
      "Preprocessed b3c24 with 823 cycles\n",
      "Preprocessed b3c25 with 987 cycles\n",
      "Preprocessed b3c26 with 1026 cycles\n",
      "Preprocessed b3c27 with 848 cycles\n",
      "Preprocessed b3c28 with 539 cycles\n",
      "Preprocessed b3c29 with 856 cycles\n",
      "Preprocessed b3c30 with 933 cycles\n",
      "Preprocessed b3c31 with 729 cycles\n",
      "Preprocessed b3c33 with 1282 cycles\n",
      "Preprocessed b3c34 with 1156 cycles\n",
      "Preprocessed b3c35 with 1091 cycles\n",
      "Preprocessed b3c36 with 921 cycles\n",
      "Preprocessed b3c38 with 1933 cycles\n",
      "Preprocessed b3c39 with 1154 cycles\n",
      "Preprocessed b3c40 with 794 cycles\n",
      "Preprocessed b3c41 with 784 cycles\n",
      "Preprocessed b3c44 with 938 cycles\n",
      "Preprocessed b3c45 with 1799 cycles\n"
     ]
    }
   ],
   "source": [
    "pre_processed_data = {}\n",
    "\n",
    "for key in batch.keys():\n",
    "  # skip the first cycle as it is initial cycle with 0 values\n",
    "  caps = batch[key]['summary']['QC'][1:]\n",
    "  \n",
    "  # remove outliers\n",
    "  cap_diff = np.abs(np.concatenate(([0], np.diff(caps))))\n",
    "  valid_idx = np.where(cap_diff < cap_outlier_diff_threshold)\n",
    "  caps = caps[valid_idx] \n",
    "  \n",
    "  #TODO: use different normalization??\n",
    "  caps = caps/1.1\n",
    "  \n",
    "  cycles = batch[key]['cycles']  \n",
    "  feats = []\n",
    "  for cycle_id in valid_idx[0]:\n",
    "    cycle = cycles[str(cycle_id)]\n",
    "    time = cycle['t']\n",
    "    current = cycle['I']\n",
    "    temp = cycle['T']\n",
    "    feat = [\n",
    "      np.trapz((current == 0).astype(np.float32), time),\n",
    "      np.trapz((current > 0).astype(np.float32), time),\n",
    "      np.trapz((current < 0).astype(np.float32), time),\n",
    "      max(current),\n",
    "      abs(min(current))\n",
    "    ]\n",
    "      \n",
    "    for t in range(math.floor(min_temp), math.ceil(max_temp), temperature_feature_interval):\n",
    "      feat = np.append(feat, np.trapz(((temp > t) & (temp <= t+temperature_feature_interval)).astype(np.float32), time))\n",
    "    # only check charging current (I>0), as the discharge cycles are constant\n",
    "    for c in range(0, math.ceil(max_current), current_feature_interval):\n",
    "      feat = np.append(feat, np.trapz(((current > c) & (current <= c+current_feature_interval)).astype(np.float32), time))\n",
    "    feats.append(feat)\n",
    "  \n",
    "  curve_ratios = []\n",
    "  random_min = curve_ratio_min\n",
    "  random_max = random_min + curve_ratio_step_size\n",
    "  for _ in range(curve_ratio_steps):\n",
    "    new_ratio = round(random.uniform(random_min, min(random_max, curve_ratio_max)), curve_ratio_digits)\n",
    "    curve_ratios.append(new_ratio)\n",
    "    random_min = new_ratio\n",
    "    random_max += curve_ratio_step_size\n",
    "  curve_ratios.append(1.0)\n",
    "  \n",
    "  print('Preprocessed', key, 'with', len(feats), 'cycles')\n",
    "  \n",
    "  pre_processed_data[key] = {\n",
    "    'capacities': torch.tensor(caps, dtype=torch.float32),\n",
    "    'features': torch.tensor(feats, dtype=torch.float32),\n",
    "    'curve_ratios': curve_ratios,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pre_processed_data, open(os.path.join(data_dir_path,'preprocessed_data.pkl'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T-LSTM-battery-degradation-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
